
R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> #r simple svm model
> 
> rm(list=ls())
> 
> 
> library(xtable) #for table creation for latex
> library(MASS)#for qda
> library(plyr)#for obtaining means by factor
> library(e1071)#for svm
> 
> #setting seed
> set.seed(76976)
> 
> w = read.table('wbc_SHAPES.txt', sep=',', header=TRUE)
> r = read.table('rbc_SHAPES.txt', sep=',', header=TRUE)
> p = read.table('plates_SHAPES.txt', sep=',', header=TRUE)
> 
> data<-rbind(w, r, p)
> 
> #eis
> ei_w = read.table('wbc.txt', sep=',', header=TRUE)
> ei_r = read.table('rbc.txt', sep=',', header=TRUE)
> ei_p = read.table('plates.txt', sep=',', header=TRUE)
> 
> ei = rbind(ei_p, ei_w, ei_r)
> sp = ei[,1]/(ei[,1]+ei[,2])
> 
> labs<-as.factor(c(rep(1, dim(w)[1]),
+                   rep(2, dim(r)[1]),
+                   rep(3, dim(p)[1])    ) )
> 
> 
> labs2<-as.factor(c(rep("Plate", dim(w)[1]),
+                   rep("White", dim(r)[1]),
+                   rep("Red", dim(p)[1])    ) )
> 
> #counts plot
> temp<-as.data.frame(cbind(sp, ei, data))
> 
> #simple model to check if it is even possible to do well with svm
> #using all of the data
> 
> test<-as.data.frame(cbind(as.factor(labs), temp))
> colnames(test)[1]<-"labs_svm"
> 
> keep<-c(1:9)
> 
> #now let's tune the svm model using 5-folds on t-set and validaiton
> 
> keep1<-which(test$labs_svm==1)
> keep2<-which(test$labs_svm==2)
> keep3<-which(test$labs_svm==3)
> 
> valid_1<-sample(keep1, floor(length(keep1)*0.30) )
> valid_2<-sample(keep2, floor(length(keep2)*0.30))
> valid_3<-sample(keep3, floor(length(keep3)*0.30) )
> 
> valid<-c(valid_1, valid_2, valid_3)
> 
> tc <- tune.control(cross = 5)
> 
> tune.out<-tune.svm(as.factor(labs_svm) ~.,
+           data=test[-valid,keep],
+           kernel='poly',
+           cost=1,
+           coef0=c(1:5, 50),
+           degree=c(2:5),
+           tunecontrol = tc,
+           scale=TRUE)
> 
> summary(tune.out)

Parameter tuning of ‘svm’:

- sampling method: 5-fold cross validation 

- best parameters:
 degree coef0 cost
      2     5    1

- best performance: 0.00526017 

- Detailed performance results:
   degree coef0 cost       error  dispersion
1       2     1    1 0.005844538 0.001460929
2       3     1    1 0.005844538 0.002732853
3       4     1    1 0.005552568 0.001905223
4       5     1    1 0.005844538 0.001033792
5       2     2    1 0.006136936 0.001222942
6       3     2    1 0.005552141 0.001600755
7       4     2    1 0.006429334 0.002447399
8       5     2    1 0.009059205 0.003486971
9       2     3    1 0.005552568 0.001224214
10      3     3    1 0.005844111 0.001788391
11      4     3    1 0.008473983 0.003777342
12      5     3    1 0.009350322 0.003359035
13      2     4    1 0.005552568 0.001224214
14      3     4    1 0.006428907 0.001306817
15      4     4    1 0.008767661 0.002737417
16      5     4    1 0.009058351 0.002396065
17      2     5    1 0.005260170 0.001667022
18      3     5    1 0.006720878 0.001305267
19      4     5    1 0.010227942 0.003723596
20      5     5    1 0.009058351 0.003327020
21      2    50    1 0.005844538 0.001790569
22      3    50    1 0.008475264 0.002617080
23      4    50    1 0.009351603 0.003365017
24      5    50    1 0.010519913 0.004548377

> 
> ypred=predict(tune.out$best.model ,test[-valid,])
> table(predict=ypred, truth=test$labs_svm[-valid])
       truth
predict    1    2    3
      1  257    1    0
      2    3 2904    5
      3    1    3  248
> mean(ypred==as.factor(as.numeric(test$labs_svm[-valid])))
[1] 0.9962011
> 
> ypred=predict(tune.out$best.model ,test[valid,])
> table(predict=ypred, truth=test$labs_svm[valid])
       truth
predict    1    2    3
      1  108    2    0
      2    3 1242    3
      3    0    1  105
> mean(ypred==as.factor(as.numeric(test$labs_svm[valid])))
[1] 0.9938525
> 
> 
> #now only using 3 variables from linear model
> keep3<-c(1, 2, 6, 9)
> tune.out<-tune.svm(as.factor(labs_svm) ~.,
+           data=test[-valid,keep3],
+           kernel='poly',
+           cost=1,
+           coef0=c(1:5, 50),
+           degree=c(2:5),
+           tunecontrol = tc,
+           scale=TRUE)

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> summary(tune.out)

Parameter tuning of ‘svm’:

- sampling method: 5-fold cross validation 

- best parameters:
 degree coef0 cost
      2     1    1

- best performance: 0.05552482 

- Detailed performance results:
   degree coef0 cost      error  dispersion
1       2     1    1 0.05552482 0.008279227
2       3     1    1 0.05669399 0.007978128
3       4     1    1 0.05610919 0.006093625
4       5     1    1 0.05844837 0.008479938
5       2     2    1 0.05581722 0.008497156
6       3     2    1 0.05640159 0.008188260
7       4     2    1 0.05581722 0.007129345
8       5     2    1 0.05786400 0.007934376
9       2     3    1 0.05581679 0.008493046
10      3     3    1 0.05757118 0.007792720
11      4     3    1 0.05669399 0.007774600
12      5     3    1 0.05844880 0.008420669
13      2     4    1 0.05581679 0.008493046
14      3     4    1 0.05786358 0.007725319
15      4     4    1 0.05698638 0.007679258
16      5     4    1 0.05844837 0.009088256
17      2     5    1 0.05581679 0.008493046
18      3     5    1 0.05757118 0.007654350
19      4     5    1 0.05786358 0.008514988
20      5     5    1 0.05844794 0.009373888
21      2    50    1 0.05581679 0.008040578
22      3    50    1 0.05786400 0.008001439
23      4    50    1 0.07598369 0.035589999
24      5    50    1 0.11045588 0.037185080

> 
> ypred=predict(tune.out$best.model ,test[-valid,])
> table(predict=ypred, truth=test$labs_svm[-valid])
       truth
predict    1    2    3
      1  108    6    0
      2  152 2897   20
      3    1    5  233
> mean(ypred==as.factor(as.numeric(test$labs_svm[-valid])))
[1] 0.9462303
> 
> ypred=predict(tune.out$best.model ,test[valid,])
> table(predict=ypred, truth=test$labs_svm[valid])
       truth
predict    1    2    3
      1   34    5    0
      2   77 1238   11
      3    0    2   97
> mean(ypred==as.factor(as.numeric(test$labs_svm[valid])))
[1] 0.9351093
> 
> #now only using 4 variables from linear model
> keep4<-c(1, 2, 4, 6, 9)
> tune.out<-tune.svm(as.factor(labs_svm) ~.,
+           data=test[-valid,keep4],
+           kernel='poly',
+           cost=1,
+           coef0=c(1:5, 50),
+           degree=c(2:5),
+           tunecontrol = tc,
+           scale=TRUE)

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> summary(tune.out)

Parameter tuning of ‘svm’:

- sampling method: 5-fold cross validation 

- best parameters:
 degree coef0 cost
      3     4    1

- best performance: 0.01198019 

- Detailed performance results:
   degree coef0 cost      error  dispersion
1       2     1    1 0.01256456 0.003663623
2       3     1    1 0.01256542 0.002847440
3       4     1    1 0.01314936 0.004131369
4       5     1    1 0.01519443 0.005224857
5       2     2    1 0.01227216 0.004206033
6       3     2    1 0.01256542 0.002443462
7       4     2    1 0.01373330 0.005326320
8       5     2    1 0.01782473 0.004995238
9       2     3    1 0.01256456 0.003663623
10      3     3    1 0.01285739 0.002397832
11      4     3    1 0.01431767 0.004775844
12      5     3    1 0.01928587 0.004048766
13      2     4    1 0.01285653 0.003915741
14      3     4    1 0.01198019 0.003634934
15      4     4    1 0.01431724 0.005692666
16      5     4    1 0.01928672 0.004780260
17      2     5    1 0.01227216 0.004330854
18      3     5    1 0.01285653 0.003775988
19      4     5    1 0.01519443 0.004685681
20      5     5    1 0.01987109 0.005328965
21      2    50    1 0.01256456 0.003806274
22      3    50    1 0.01519358 0.004563870
23      4    50    1 0.01870150 0.005101091
24      5    50    1 0.02074657 0.005400457

> 
> ypred=predict(tune.out$best.model ,test[-valid,])
> table(predict=ypred, truth=test$labs_svm[-valid])
       truth
predict    1    2    3
      1  254    2    0
      2    7 2899   18
      3    0    7  235
> mean(ypred==as.factor(as.numeric(test$labs_svm[-valid])))
[1] 0.9900643
> 
> ypred=predict(tune.out$best.model ,test[valid,])
> table(predict=ypred, truth=test$labs_svm[valid])
       truth
predict    1    2    3
      1  105    6    0
      2    6 1237   12
      3    0    2   96
> mean(ypred==as.factor(as.numeric(test$labs_svm[valid])))
[1] 0.9822404
> 
> 
> #
> 
> proc.time()
   user  system elapsed 
224.612   0.033 224.630 
