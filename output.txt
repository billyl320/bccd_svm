
R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> #r simple svm model
> 
> rm(list=ls())
> 
> 
> library(xtable) #for table creation for latex
> library(MASS)#for qda
> library(plyr)#for obtaining means by factor
> library(e1071)#for svm
> 
> #defining proper scientific notation
> 
> data = read.table('ultima.csv', sep=',', header=TRUE)
> 
> #eis
> ei_w = read.table('wbc.txt', sep=',', header=TRUE)
> ei_r = read.table('rbc.txt', sep=',', header=TRUE)
> ei_p = read.table('plates.txt', sep=',', header=TRUE)
> 
> ei = rbind(ei_p, ei_w, ei_r)
> 
> #data cleaning
> 
> labs2<-as.factor(c(rep("Plate", table(data$train)[1]),
+                   rep("White", table(data$train)[2]),
+                   rep("Red", table(data$train)[3])    ) )
> 
> 
> temp<-as.data.frame(cbind(ei, data))
> 
> mydata<-as.data.frame(cbind(as.factor(temp$train), temp[,-3]))
> colnames(mydata)[1]<-"labs_svm"
> 
> keep<-c(1:9)
> 
> #now let's tune the svm model using 5-folds on t-set and validaiton
> 
> keep1<-which(mydata$labs_svm==1)
> keep2<-which(mydata$labs_svm==2)
> keep3<-which(mydata$labs_svm==3)
> 
> valid_1<-sample(keep1, floor(length(keep1)*0.30) )
> valid_2<-sample(keep2, floor(length(keep2)*0.30))
> valid_3<-sample(keep3, floor(length(keep3)*0.30) )
> 
> valid<-c(valid_1, valid_2, valid_3)
> 
> tc <- tune.control(cross = 5)
> 
> tune.out<-tune(svm, as.factor(labs_svm) ~.,
+           data=mydata[-valid,keep],
+           kernel='polynomial',
+           ranges=list(cost=1, coef0=c(1:5, 50), degree=c(2:5)) ,
+           #validation.x=valid2[,-1],
+           #validation.y=as.factor(valid2[,1]),
+           tunecontrol = tc)

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> summary(tune.out)

Parameter tuning of ‘svm’:

- sampling method: 5-fold cross validation 

- best parameters:
 cost coef0 degree
    1     1      3

- best performance: 0.01957954 

- Detailed performance results:
   cost coef0 degree      error  dispersion
1     1     1      2 0.02045546 0.004955512
2     1     2      2 0.02045546 0.004000932
3     1     3      2 0.02103983 0.004688755
4     1     4      2 0.02074743 0.004181687
5     1     5      2 0.02045546 0.004000932
6     1    50      2 0.01957997 0.004695728
7     1     1      3 0.01957954 0.003034356
8     1     2      3 0.02016349 0.003167687
9     1     3      3 0.02045503 0.002915480
10    1     4      3 0.02103940 0.003661392
11    1     5      3 0.02074743 0.003777703
12    1    50      3 0.02191617 0.004127618
13    1     1      4 0.02133222 0.003946163
14    1     2      4 0.02162462 0.004432002
15    1     3      4 0.02308448 0.004174606
16    1     4      4 0.02279250 0.004072525
17    1     5      4 0.02220814 0.003911944
18    1    50      4 0.02542195 0.003010453
19    1     1      5 0.02366927 0.004770904
20    1     2      5 0.02366884 0.004768812
21    1     3      5 0.02337773 0.004842307
22    1     4      5 0.02367098 0.004188252
23    1     5      5 0.02425492 0.003363674
24    1    50      5 0.03038673 0.011455673

> 
> ypred=predict(tune.out$best.model ,mydata[-valid,])
> table(predict=ypred, truth=mydata$labs_svm[-valid])
       truth
predict    1    2    3
      1  249    1    1
      2    0  213    6
      3    4   47 2901
> mean(ypred==as.factor(as.numeric(mydata$labs_svm[-valid])))
[1] 0.9827586
> 
> ypred=predict(tune.out$best.model ,mydata[valid,])
> table(predict=ypred, truth=mydata$labs_svm[valid])
       truth
predict    1    2    3
      1  106    1    6
      2    0   93    3
      3    2   17 1236
> mean(ypred==as.factor(as.numeric(mydata$labs_svm[valid])))
[1] 0.9801913
> 
> 
> #now doing it via kfolds and t-set and validation
> 
> 
> 
> 
> #
> 
> proc.time()
   user  system elapsed 
 97.270   0.692  98.702 
